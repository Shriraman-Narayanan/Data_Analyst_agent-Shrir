
# **TDS Data Analyst Agent**

> ğŸ§  Autonomous AI-powered Data Analyst â€” source, prepare, analyze & visualize data from natural language instructions.

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)
![Framework](https://img.shields.io/badge/Framework-Flask-orange?logo=flask)

---

## ğŸš€ Overview

The **TDS Data Analyst Agent** is a **Reason + Act (ReAct)** AI framework powered by an LLM that can dynamically perform **data sourcing, cleaning, analysis, and visualization**.
It intelligently chooses tools, generates Python code, and executes it securely â€” handling everything from **web scraping** to **large dataset queries** and **custom charts**.

---

## âœ¨ Features

* ğŸ¤– **Agentic Framework** â€“ LLM selects and uses tools based on tasks.
* âš¡ **Dynamic Code Execution** â€“ Generates Python code for Pandas, NumPy, Matplotlib, etc.
* ğŸ”’ **Secure Sandbox** â€“ Isolated environment prevents malicious actions.
* ğŸ›  **Toolbox**:

  * Python REPL for data analysis
  * Web Scraper for real-time data fetching
  * File system tools for secure file handling
* ğŸ”„ **Resilience** â€“ Detects errors, retries with self-corrections.
* â˜ **Deployment Ready** â€“ Pre-configured with Docker & Render YAML.

---

## ğŸ“‚ Project Structure

```
data-analyst-agent/
â”‚
â”œâ”€â”€ workspaces/         # Temp storage for each request
â”‚
â”œâ”€â”€ app.py              # Flask API application
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ Dockerfile          # Container build config
â”œâ”€â”€ render.yaml         # Render deployment config
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”‚
â””â”€â”€ agent/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ agent.py        # ReAct agent logic
    â”œâ”€â”€ prompts.py      # System prompts for LLM
    â””â”€â”€ tools.py        # Tool definitions
```

---

## âš™ï¸ Setup

<details>
<summary><strong>ğŸ“Œ Local Installation</strong></summary>

**Prerequisites**

* Python 3.9+
* Pip
* Git

**Steps**

```bash
# Clone repository
git clone <your-repo-url>
cd data-analyst-agent

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Add your API key
echo 'GENAI_API_KEY="your_google_ai_studio_api_key"' > .env

# Run the application
gunicorn app:app
```

App runs on: `http://127.0.0.1:8000`

</details>

---

## â˜ Deployment to Render

<details>
<summary><strong>ğŸš€ Render Deployment Guide</strong></summary>

1. Push code to a **public GitHub repo**.
2. On **Render Dashboard** â†’ Click **New Web Service**.
3. Connect your repo.
4. Render detects `render.yaml` â†’ Configure service name â†’ Deploy.
5. Your API will be live at the provided Render URL.

</details>

---

## ğŸ§ª API Usage

**Endpoint:** `/api/`
**Method:** `POST`
**Type:** `multipart/form-data`

**Required:**

* `questions.txt` â†’ Contains natural language instructions for the agent.

**Optional:**

* Additional data files (CSV, PNG, etc.) for analysis.

**Example Request:**

```bash
curl -X POST https://your-render-app-url/api/ \
     -F "questions.txt=@path/to/questions.txt" \
     -F "data.csv=@path/to/data.csv"
```

**Example Response:**

```json
{
  "status": "success",
  "answers": [
    "Data summary generated...",
    "Visualization saved as chart.png"
  ]
}
```

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See [LICENSE](LICENSE) for details.

---
